#!/usr/bin/env python3
"""
‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
Advanced Statistical Analysis for Election Data
"""

import numpy as np
import pandas as pd
from scipy import stats
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
from collections import Counter
import math


class AdvancedElectionAnalytics:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    
    def __init__(self):
        self.benford_expected = self._calculate_benford_distribution()
    
    def _calculate_benford_distribution(self) -> Dict[int, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ï‡∏≤‡∏° Benford's Law"""
        return {d: math.log10(1 + 1/d) for d in range(1, 10)}
    
    def benford_law_test(self, data: List[int]) -> Dict:
        """
        ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Benford's Law
        
        Benford's Law: ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÄ‡∏•‡∏Ç‡∏´‡∏•‡∏±‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ï‡∏≤‡∏°
        P(d) = log10(1 + 1/d)
        
        ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏õ‡∏•‡∏≠‡∏°‡πÅ‡∏õ‡∏•‡∏á ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏ô‡∏µ‡πâ
        """
        # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏•‡∏Ç‡∏´‡∏•‡∏±‡∏Å‡∏´‡∏ô‡πâ‡∏≤
        first_digits = [int(str(abs(x))[0]) for x in data if x > 0]
        
        if len(first_digits) < 30:
            return {
                'valid': False,
                'reason': '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏ï‡πâ‡∏≠‡∏á >= 30 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)',
                'sample_size': len(first_digits)
            }
        
        # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
        observed_freq = Counter(first_digits)
        total = len(first_digits)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Chi-Square
        chi_square = 0
        details = {}
        
        for digit in range(1, 10):
            observed = observed_freq.get(digit, 0)
            expected = self.benford_expected[digit] * total
            
            if expected > 0:
                chi_square += ((observed - expected) ** 2) / expected
            
            details[digit] = {
                'observed': observed,
                'observed_pct': (observed / total) * 100,
                'expected': expected,
                'expected_pct': self.benford_expected[digit] * 100
            }
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà df = 8 (9 digits - 1)
        p_value = 1 - stats.chi2.cdf(chi_square, df=8)
        
        return {
            'valid': True,
            'chi_square': chi_square,
            'p_value': p_value,
            'conforms_to_benford': p_value > 0.05,  # ‡∏ñ‡πâ‡∏≤ > 0.05 ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏Å‡∏é
            'details': details,
            'interpretation': self._interpret_benford_result(p_value)
        }
    
    def _interpret_benford_result(self, p_value: float) -> str:
        """‡πÅ‡∏õ‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ú‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö"""
        if p_value > 0.05:
            return "‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏° Benford's Law (‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏õ‡∏•‡∏≠‡∏°‡πÅ‡∏õ‡∏•‡∏á)"
        elif p_value > 0.01:
            return "‚ö†Ô∏è  ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
        else:
            return "üö® ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏° Benford's Law (‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏ß‡πà‡∏≤‡∏ñ‡∏π‡∏Å‡∏õ‡∏•‡∏≠‡∏°‡πÅ‡∏õ‡∏•‡∏á)"
    
    def detect_vote_stuffing_patterns(self, df: pd.DataFrame) -> Dict:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏£ pattern ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£
        
        ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì:
        1. ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏°‡πÜ (round numbers) ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        2. ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏ï‡πà‡∏≥‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
        3. ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏ö‡∏ö linear ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        """
        results = {
            'round_numbers': self._check_round_numbers(df),
            'variance_analysis': self._analyze_variance(df),
            'linear_patterns': self._check_linear_patterns(df)
        }
        
        return results
    
    def _check_round_numbers(self, df: pd.DataFrame) -> Dict:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Å‡∏•‡∏°‡πÜ"""
        if 'votes' not in df.columns:
            return {'valid': False}
        
        votes = df['votes'].values
        round_nums = sum(1 for v in votes if v % 100 == 0 or v % 50 == 0)
        total = len(votes)
        
        round_pct = (round_nums / total) * 100
        
        return {
            'round_numbers_count': round_nums,
            'total_count': total,
            'percentage': round_pct,
            'suspicious': round_pct > 20,  # ‡∏ñ‡πâ‡∏≤ > 20% ‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢
            'interpretation': f"{'üö® ‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢' if round_pct > 20 else '‚úÖ ‡∏õ‡∏Å‡∏ï‡∏¥'}: {round_pct:.1f}% ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏Å‡∏•‡∏°‡πÜ"
        }
    
    def _analyze_variance(self, df: pd.DataFrame) -> Dict:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô"""
        if 'votes' not in df.columns:
            return {'valid': False}
        
        votes = df['votes'].values
        variance = np.var(votes)
        std_dev = np.std(votes)
        cv = (std_dev / np.mean(votes)) * 100  # Coefficient of Variation
        
        return {
            'variance': variance,
            'std_dev': std_dev,
            'coefficient_of_variation': cv,
            'suspicious': cv < 10,  # CV ‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å ‡∏≠‡∏≤‡∏à‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á
            'interpretation': f"{'üö® ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏ï‡πà‡∏≥‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥' if cv < 10 else '‚úÖ ‡∏õ‡∏Å‡∏ï‡∏¥'}: CV = {cv:.1f}%"
        }
    
    def _check_linear_patterns(self, df: pd.DataFrame) -> Dict:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ linear patterns"""
        if 'votes' not in df.columns or len(df) < 10:
            return {'valid': False}
        
        votes = df['votes'].values
        x = np.arange(len(votes))
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì correlation
        correlation = np.corrcoef(x, votes)[0, 1]
        
        return {
            'correlation': correlation,
            'highly_linear': abs(correlation) > 0.95,
            'suspicious': abs(correlation) > 0.95,
            'interpretation': f"{'üö® ‡πÄ‡∏õ‡πá‡∏ô linear ‡∏°‡∏≤‡∏Å‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥' if abs(correlation) > 0.95 else '‚úÖ ‡∏õ‡∏Å‡∏ï‡∏¥'}: r = {correlation:.3f}"
        }
    
    def compare_with_historical_data(self, current: pd.DataFrame, 
                                     historical: pd.DataFrame) -> Dict:
        """
        ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô
        
        ‡∏´‡∏≤ swing ‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
        """
        if 'constituency_id' not in current.columns:
            return {'valid': False}
        
        merged = pd.merge(current, historical, 
                         on='constituency_id', 
                         suffixes=('_current', '_historical'))
        
        if 'votes_current' in merged.columns and 'votes_historical' in merged.columns:
            merged['swing'] = ((merged['votes_current'] - merged['votes_historical']) / 
                              merged['votes_historical']) * 100
            
            # ‡∏´‡∏≤ outliers
            Q1 = merged['swing'].quantile(0.25)
            Q3 = merged['swing'].quantile(0.75)
            IQR = Q3 - Q1
            
            outliers = merged[
                (merged['swing'] < Q1 - 1.5 * IQR) | 
                (merged['swing'] > Q3 + 1.5 * IQR)
            ]
            
            return {
                'valid': True,
                'mean_swing': merged['swing'].mean(),
                'median_swing': merged['swing'].median(),
                'outliers_count': len(outliers),
                'outliers': outliers[['constituency_id', 'swing']].to_dict('records'),
                'interpretation': f"‡∏û‡∏ö {len(outliers)} ‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ swing ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥"
            }
        
        return {'valid': False}
    
    def spatial_autocorrelation(self, df: pd.DataFrame) -> Dict:
        """
        ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Spatial Autocorrelation (Moran's I)
        
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏Ç‡∏ï‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        ‡∏´‡∏≤‡∏Å‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏≠‡∏≤‡∏à‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏Å‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
        """
        # Placeholder - ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• geospatial ‡∏à‡∏£‡∏¥‡∏á
        return {
            'valid': False,
            'reason': '‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• latitude, longitude',
            'note': '‡πÉ‡∏ä‡πâ pysal ‡∏´‡∏£‡∏∑‡∏≠ geopandas ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö'
        }
    
    def generate_full_report(self, df: pd.DataFrame) -> Dict:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î"""
        report = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'total_constituencies': len(df),
            'analyses': {}
        }
        
        # Benford's Law
        if 'votes' in df.columns:
            votes_list = df['votes'].dropna().astype(int).tolist()
            if len(votes_list) >= 30:
                report['analyses']['benford_law'] = self.benford_law_test(votes_list)
        
        # Vote Stuffing Patterns
        report['analyses']['vote_stuffing'] = self.detect_vote_stuffing_patterns(df)
        
        # Overall Assessment
        suspicious_flags = 0
        
        if 'benford_law' in report['analyses']:
            if not report['analyses']['benford_law'].get('conforms_to_benford', True):
                suspicious_flags += 1
        
        if report['analyses']['vote_stuffing']['round_numbers'].get('suspicious', False):
            suspicious_flags += 1
        
        if report['analyses']['vote_stuffing']['variance_analysis'].get('suspicious', False):
            suspicious_flags += 1
        
        report['risk_level'] = self._calculate_risk_level(suspicious_flags)
        
        return report
    
    def _calculate_risk_level(self, flags: int) -> str:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"""
        if flags == 0:
            return "üü¢ LOW - ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢"
        elif flags == 1:
            return "üü° MEDIUM - ‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢ 1 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
        elif flags == 2:
            return "üü† HIGH - ‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏î‡πà‡∏ß‡∏ô"
        else:
            return "üî¥ CRITICAL - ‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≠‡∏ö‡∏™‡∏ß‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ"


def demo_analysis():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
    print("=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ ===\n")
    
    analytics = AdvancedElectionAnalytics()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    np.random.seed(42)
    
    # ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥ (‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏° Benford)
    normal_data = np.random.lognormal(mean=8, sigma=2, size=200).astype(int)
    
    # ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≠‡∏° (uniform distribution - ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏° Benford)
    fake_data = np.random.randint(1000, 9999, size=200)
    
    print("1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥:")
    result1 = analytics.benford_law_test(normal_data.tolist())
    print(f"   Chi-square: {result1['chi_square']:.3f}")
    print(f"   P-value: {result1['p_value']:.3f}")
    print(f"   {result1['interpretation']}\n")
    
    print("2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≠‡∏°:")
    result2 = analytics.benford_law_test(fake_data.tolist())
    print(f"   Chi-square: {result2['chi_square']:.3f}")
    print(f"   P-value: {result2['p_value']:.3f}")
    print(f"   {result2['interpretation']}\n")
    
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á DataFrame
    df = pd.DataFrame({
        'constituency_id': range(100),
        'votes': normal_data[:100]
    })
    
    print("3. ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏¢‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£:")
    stuffing_result = analytics.detect_vote_stuffing_patterns(df)
    print(f"   {stuffing_result['round_numbers']['interpretation']}")
    print(f"   {stuffing_result['variance_analysis']['interpretation']}")
    print(f"   {stuffing_result['linear_patterns']['interpretation']}\n")
    
    print("4. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°:")
    full_report = analytics.generate_full_report(df)
    print(f"   Risk Level: {full_report['risk_level']}")


if __name__ == "__main__":
    demo_analysis()
